{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1\n",
    "\n",
    "**Target Task:** Cora \n",
    "\n",
    "**Transfer learning Source Task:** Citeseer\n",
    "\n",
    "**Meta-learning Source Task:** Citeseer, Pubmed\n",
    "***\n",
    "## Installs & imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ! pip install torch==1.5.0+cu101 torchvision==0.6.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "\n",
    "# ! pip install torch-scatter==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.5.0.html\n",
    "# ! pip install torch-sparse==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.5.0.html\n",
    "# ! pip install torch-cluster==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.5.0.html\n",
    "# ! pip install torch-spline-conv==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.5.0.html\n",
    "# ! pip install torch-geometric\n",
    "\n",
    "# ! pip install --ignore-installed \"jsonschema>=2.6.0,<3.1.0\"\n",
    "! pip install comet_ml --upgrade --ignore-installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from comet_ml import Experiment\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "from torch_geometric.nn import GCNConv, SAGEConv, GATConv, VGAE\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Data & Experiment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cora\n",
      "-----\n",
      "2708 Nodes; 10556 Edges\n",
      "No. of features: 1433\n",
      "No. of classes: 7\n"
     ]
    }
   ],
   "source": [
    "proj_name = 'experiment-1'\n",
    "\n",
    "cora = Planetoid('./data', 'Cora')\n",
    "\n",
    "print('Cora')\n",
    "print('-----')\n",
    "print('{} Nodes; {} Edges'.format(cora[0].num_nodes, cora[0].num_edges))\n",
    "print('No. of features: {}'.format(cora[0].num_features))\n",
    "print('No. of classes: {}'.format(cora.num_classes))\n",
    "\n",
    "cora_data = cora[0].to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Training base models on Cora\n",
    "\n",
    "### GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn_hyperparams = {\n",
    "    'hidden_dim' : 256,\n",
    "    'n_features' : cora[0].num_features,\n",
    "    'n_classes' : cora.num_classes,\n",
    "    'learning_rate': 0.001,\n",
    "    'num_epochs': 200,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_dim, n_features, n_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(n_features, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, n_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training GCN on Cora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/graph-net-experiments/experiment-1/5b88affff91047ad9e9dcfce1a9044aa\n",
      "\n",
      "100%|██████████| 200/200 [00:02<00:00, 70.18it/s]\n",
      "COMET INFO: Uploading stats to Comet before program termination (may take several seconds)\n"
     ]
    }
   ],
   "source": [
    "experiment = Experiment(project_name=proj_name, display_summary_level=0)\n",
    "experiment.log_parameters(gcn_hyperparams)\n",
    "experiment.add_tags(['GCN', 'Base'])\n",
    "\n",
    "gcn = GCN(hidden_dim=gcn_hyperparams['hidden_dim'],\n",
    "        n_features=gcn_hyperparams['n_features'],\n",
    "        n_classes=gcn_hyperparams['n_classes']\n",
    "        ).to(device)\n",
    "                             \n",
    "optimizer = torch.optim.Adam(gcn.parameters(), lr=gcn_hyperparams['learning_rate'])\n",
    "\n",
    "for epoch in tqdm(range(gcn_hyperparams['num_epochs'])):\n",
    "    # Training\n",
    "    gcn.train()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    out = gcn(cora_data)\n",
    "    loss = F.nll_loss(out[cora_data.train_mask], cora_data.y[cora_data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    experiment.log_metric('loss', loss.item(), step=epoch)\n",
    "\n",
    "    # Validation\n",
    "    gcn.eval()\n",
    "    \n",
    "    _, pred = gcn(cora_data).max(dim=1)\n",
    "    f1 = f1_score(\n",
    "        cora_data.y[cora_data.val_mask].cpu().numpy(),\n",
    "        pred[cora_data.val_mask].cpu().numpy(),\n",
    "        average='weighted'\n",
    "    )\n",
    "\n",
    "    experiment.log_metric('test_F1_score', f1, step=epoch)\n",
    "    \n",
    "experiment.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GVAE\n",
    "\n",
    "See [PyG example](https://github.com/rusty1s/pytorch_geometric/blob/master/examples/autoencoder.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(test_neg_edge_index=[2, 527], test_pos_edge_index=[2, 527], train_neg_adj_mask=[2708, 2708], train_pos_edge_index=[2, 8976], val_neg_edge_index=[2, 263], val_pos_edge_index=[2, 263], x=[2708, 1433])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gvae_hyperparams = {\n",
    "    'hidden_dim' : 256,\n",
    "    'n_features' : cora[0].num_features,\n",
    "    'n_classes' : cora.num_classes,\n",
    "    'learning_rate': 0.001,\n",
    "    'num_epochs': 200,\n",
    "}\n",
    "\n",
    "cora_data_new = copy.copy(cora_data)\n",
    "cora_data_new.train_mask = cora_data_new.val_mask = cora_data_new.test_mask = cora_data_new.y = None\n",
    "cora_data_new = train_test_split_edges(cora_data_new)\n",
    "cora_data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_dim, n_features, n_classes):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv1 = GCNConv(n_features, hidden_dim)\n",
    "        self.conv_mu = GCNConv(hidden_dim, n_classes)\n",
    "        self.conv_logvar = GCNConv(hidden_dim, n_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.train_pos_edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        return self.conv_mu(x, edge_index), self.conv_logvar(x, edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/graph-net-experiments/experiment-1/c277037d3c414528b3fe6a00351ecf1a\n",
      "\n",
      "100%|██████████| 200/200 [00:10<00:00, 18.32it/s]\n",
      "COMET INFO: Uploading stats to Comet before program termination (may take several seconds)\n"
     ]
    }
   ],
   "source": [
    "experiment = Experiment(project_name=proj_name, display_summary_level=0)\n",
    "experiment.log_parameters(gvae_hyperparams)\n",
    "experiment.add_tags(['GVAE', 'Base'])\n",
    "\n",
    "gvae = VGAE(Encoder(\n",
    "        hidden_dim=gvae_hyperparams['hidden_dim'],\n",
    "        n_features=gvae_hyperparams['n_features'],\n",
    "        n_classes=gvae_hyperparams['n_classes']\n",
    "    )).to(device)\n",
    "                             \n",
    "optimizer = torch.optim.Adam(gvae.parameters(), lr=gvae_hyperparams['learning_rate'])\n",
    "\n",
    "for epoch in tqdm(range(gvae_hyperparams['num_epochs'])):\n",
    "    # Training\n",
    "    gvae.train()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    z = gvae.encode(cora_data_new)\n",
    "    gvae.recon_loss(z, cora_data_new.train_pos_edge_index)\n",
    "    loss = gvae.recon_loss(z, cora_data_new.train_pos_edge_index) + (1 / cora_data_new.num_nodes) * gvae.kl_loss()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    experiment.log_metric('loss', loss.item(), step=epoch)\n",
    "\n",
    "    # Validation\n",
    "    gvae.eval()\n",
    "    with torch.no_grad():\n",
    "        z = gvae.encode(cora_data_new)\n",
    "    auc, ap = gvae.test(z, cora_data_new.val_pos_edge_index, cora_data_new.val_neg_edge_index)\n",
    "\n",
    "    experiment.log_metric('auc', auc, step=epoch)\n",
    "    experiment.log_metric('ap', ap, step=epoch)\n",
    "\n",
    "    \n",
    "experiment.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GraphSAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphsage_hyperparams = {\n",
    "    'hidden_dim' : 256,\n",
    "    'n_features' : cora[0].num_features,\n",
    "    'n_classes' : cora.num_classes,\n",
    "    'learning_rate': 0.001,\n",
    "    'num_epochs': 200,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, hidden_dim, n_features, n_classes):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(n_features, hidden_dim)\n",
    "        self.conv2 = SAGEConv(hidden_dim, n_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/graph-net-experiments/experiment-1/db4852b3b7e94fc7b06b424e39cf1767\n",
      "\n",
      "100%|██████████| 200/200 [00:04<00:00, 43.18it/s]\n",
      "COMET INFO: Uploading stats to Comet before program termination (may take several seconds)\n"
     ]
    }
   ],
   "source": [
    "experiment = Experiment(project_name=proj_name, display_summary_level=0)\n",
    "experiment.log_parameters(graphsage_hyperparams)\n",
    "experiment.add_tags(['GraphSAGE', 'Base'])\n",
    "\n",
    "graphsage = GraphSAGE(hidden_dim=graphsage_hyperparams['hidden_dim'],\n",
    "        n_features=graphsage_hyperparams['n_features'],\n",
    "        n_classes=graphsage_hyperparams['n_classes']\n",
    "        ).to(device)\n",
    "                             \n",
    "optimizer = torch.optim.Adam(graphsage.parameters(), lr=graphsage_hyperparams['learning_rate'])\n",
    "\n",
    "for epoch in tqdm(range(graphsage_hyperparams['num_epochs'])):\n",
    "    # Training\n",
    "    graphsage.train()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    out = graphsage(cora_data)\n",
    "    loss = F.nll_loss(out[cora_data.train_mask], cora_data.y[cora_data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    experiment.log_metric('loss', loss.item(), step=epoch)\n",
    "\n",
    "    # Validation\n",
    "    graphsage.eval()\n",
    "    \n",
    "    _, pred = graphsage(cora_data).max(dim=1)\n",
    "    f1 = f1_score(\n",
    "        cora_data.y[cora_data.val_mask].cpu().numpy(),\n",
    "        pred[cora_data.val_mask].cpu().numpy(),\n",
    "        average='weighted'\n",
    "    )\n",
    "    \n",
    "    experiment.log_metric('test_F1_score', f1, step=epoch)\n",
    "    \n",
    "experiment.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gvae.test?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "gat_hyperparams = {\n",
    "    'hidden_dim' : 256,\n",
    "    'n_features' : cora[0].num_features,\n",
    "    'n_classes' : cora.num_classes,\n",
    "    'learning_rate': 0.001,\n",
    "    'num_epochs': 200,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, hidden_dim, n_features, n_classes):\n",
    "        super(GAT, self).__init__()\n",
    "        self.conv1 = GATConv(n_features, hidden_dim)\n",
    "        self.conv2 = GATConv(hidden_dim, n_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/graph-net-experiments/experiment-1/fe47b05265584e43ad0212f9262d767a\n",
      "\n",
      "100%|██████████| 200/200 [00:04<00:00, 40.66it/s]\n",
      "COMET INFO: Uploading stats to Comet before program termination (may take several seconds)\n"
     ]
    }
   ],
   "source": [
    "experiment = Experiment(project_name=proj_name, display_summary_level=0)\n",
    "experiment.log_parameters(gat_hyperparams)\n",
    "experiment.add_tags(['GAT', 'Base'])\n",
    "\n",
    "gat = GAT(hidden_dim=gat_hyperparams['hidden_dim'],\n",
    "        n_features=gat_hyperparams['n_features'],\n",
    "        n_classes=gat_hyperparams['n_classes']\n",
    "        ).to(device)\n",
    "                             \n",
    "optimizer = torch.optim.Adam(gat.parameters(), lr=gat_hyperparams['learning_rate'])\n",
    "\n",
    "for epoch in tqdm(range(gat_hyperparams['num_epochs'])):\n",
    "    # Training\n",
    "    gat.train()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    out = gat(cora_data)\n",
    "    loss = F.nll_loss(out[cora_data.train_mask], cora_data.y[cora_data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    experiment.log_metric('loss', loss.item(), step=epoch)\n",
    "\n",
    "    # Validation\n",
    "    gat.eval()\n",
    "    \n",
    "    _, pred = gat(cora_data).max(dim=1)\n",
    "    f1 = f1_score(\n",
    "        cora_data.y[cora_data.val_mask].cpu().numpy(),\n",
    "        pred[cora_data.val_mask].cpu().numpy(),\n",
    "        average='weighted'\n",
    "    )\n",
    "    \n",
    "    experiment.log_metric('test_F1_score', f1, step=epoch)\n",
    "    \n",
    "experiment.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
